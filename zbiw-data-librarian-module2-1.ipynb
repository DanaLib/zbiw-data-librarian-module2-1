{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZBIW-Zertifikatskurs \"Data Librarian\"\n",
    "# Modul 2.1: Strukturierte Daten und Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiederholung: Lesen und Schreiben von Textdateien in Python\n",
    "\n",
    "Die zentrale Funktion zum Öffnen von Dateien ist `open`. Neben dem obligatorischen Dateipfad-Argument nimmt diese Funktion einen Modus-Parameter entgegen. Der Rückgabetyp der Funktion ist standardmäßig ein `TextIOWrapper`-Objekt, welches es erlaubt, den Inhalt der Datei als String (`str`) einzulesen.\n",
    "\n",
    "Reminder: Ebenso, wie wir in der Lektion **Text-** und **Binärdatenformate** unterschieden haben, ermöglicht auch Python die Behandlung einer Datei entweder im Text- oder Binärmodus. Der Textmodus ist für die `open`-Funktion Standard (impliziter Parameter `t`) - den Binärmodus erzwingt man mit dem Parameter `b`. \n",
    "\n",
    "Weitere optionale Parameter erlauben die Spezifikation von Encoding oder der Behandlung von Zeilenumbrüchen. Weitere Informationen in der [Dokumentation](https://docs.python.org/3/library/functions.html#open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'read-only' Modus öffnen (Textmodus)\n",
    "file_for_reading = open('data/lorem_ipsum.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file_for_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distinctio'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eine bestimmte Anzahl Zeichen einlesen mit read()\n",
    "first_10_chars = file_for_reading.read(10)\n",
    "first_10_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' soluta deleniti quidem maiores et sed voluptas. Qui est quis libero dolor. Illo omnis quibusdam molestias et quis nam repudiandae sint.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eine ganze Zeile einlesen mit readline()\n",
    "next_line = file_for_reading.readline()\n",
    "next_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'Impedit quod repellendus dolor. Earum est dolorem non voluptas aut. Cum corporis aut aspernatur consequatur vel aut sit qui. Veniam sit dolorem omnis amet facilis nobis dolor. Eum magni sunt quia libero. Fuga voluptatem et voluptatem aut veritatis possimus.\\n',\n",
       " '\\n',\n",
       " 'Illum et deleniti nisi ex autem eum. Eveniet cum porro enim vitae sint consectetur. Fugit aut fugit inventore omnis. Quidem sint quia reprehenderit quae molestiae quia. Id facere similique et.\\n',\n",
       " '\\n',\n",
       " 'Vero dignissimos aspernatur ex qui architecto. Ipsam repellendus sit ipsa. Nihil eligendi accusamus esse repudiandae debitis. Dolore eligendi aut enim dolorem.\\n',\n",
       " '\\n',\n",
       " 'Esse dicta hic id. Alias alias mollitia nihil porro voluptatem sit et. Maiores sint autem numquam.\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# den gesamten Inhalt der Datei Zeile für Zeile einlesen\n",
    "whole_text = file_for_reading.readlines()\n",
    "whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nach getaner Arbeit muss die Datei wieder geschlossen werden:\n",
    "file_for_reading.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# besser: 'with' Block benutzen, damit Dateien automatisch geschlossen werden\n",
    "with open('data/lorem_ipsum.txt', 'r') as infile:\n",
    "    data = infile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` ist nun ein Listenobjekt, wobei jedes Listenelement eine Textzeile aus der Datei enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Distinctio soluta deleniti quidem maiores et sed voluptas. Qui est quis libero dolor. Illo omnis quibusdam molestias et quis nam repudiandae sint.\\n',\n",
       " '\\n',\n",
       " 'Impedit quod repellendus dolor. Earum est dolorem non voluptas aut. Cum corporis aut aspernatur consequatur vel aut sit qui. Veniam sit dolorem omnis amet facilis nobis dolor. Eum magni sunt quia libero. Fuga voluptatem et voluptatem aut veritatis possimus.\\n',\n",
       " '\\n',\n",
       " 'Illum et deleniti nisi ex autem eum. Eveniet cum porro enim vitae sint consectetur. Fugit aut fugit inventore omnis. Quidem sint quia reprehenderit quae molestiae quia. Id facere similique et.\\n',\n",
       " '\\n',\n",
       " 'Vero dignissimos aspernatur ex qui architecto. Ipsam repellendus sit ipsa. Nihil eligendi accusamus esse repudiandae debitis. Dolore eligendi aut enim dolorem.\\n',\n",
       " '\\n',\n",
       " 'Esse dicta hic id. Alias alias mollitia nihil porro voluptatem sit et. Maiores sint autem numquam.\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Iterieren über die einzelnen Zeilen ist ebenfalls möglich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinctio soluta deleniti quidem maiores et sed voluptas. Qui est quis libero dolor. Illo omnis quibusdam molestias et quis nam repudiandae sint.\n",
      "\n",
      "Impedit quod repellendus dolor. Earum est dolorem non voluptas aut. Cum corporis aut aspernatur consequatur vel aut sit qui. Veniam sit dolorem omnis amet facilis nobis dolor. Eum magni sunt quia libero. Fuga voluptatem et voluptatem aut veritatis possimus.\n",
      "\n",
      "Illum et deleniti nisi ex autem eum. Eveniet cum porro enim vitae sint consectetur. Fugit aut fugit inventore omnis. Quidem sint quia reprehenderit quae molestiae quia. Id facere similique et.\n",
      "\n",
      "Vero dignissimos aspernatur ex qui architecto. Ipsam repellendus sit ipsa. Nihil eligendi accusamus esse repudiandae debitis. Dolore eligendi aut enim dolorem.\n",
      "\n",
      "Esse dicta hic id. Alias alias mollitia nihil porro voluptatem sit et. Maiores sint autem numquam.\n"
     ]
    }
   ],
   "source": [
    "with open('data/lorem_ipsum.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        print(line.strip()) # entferne überflüssigen Whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann den Code noch etwas verkürzen, wenn man die Referenz auf `infile` nicht zusätzlich benötigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinctio soluta deleniti quidem maiores et sed voluptas. Qui est quis libero dolor. Illo omnis quibusdam molestias et quis nam repudiandae sint.\n",
      "\n",
      "Impedit quod repellendus dolor. Earum est dolorem non voluptas aut. Cum corporis aut aspernatur consequatur vel aut sit qui. Veniam sit dolorem omnis amet facilis nobis dolor. Eum magni sunt quia libero. Fuga voluptatem et voluptatem aut veritatis possimus.\n",
      "\n",
      "Illum et deleniti nisi ex autem eum. Eveniet cum porro enim vitae sint consectetur. Fugit aut fugit inventore omnis. Quidem sint quia reprehenderit quae molestiae quia. Id facere similique et.\n",
      "\n",
      "Vero dignissimos aspernatur ex qui architecto. Ipsam repellendus sit ipsa. Nihil eligendi accusamus esse repudiandae debitis. Dolore eligendi aut enim dolorem.\n",
      "\n",
      "Esse dicta hic id. Alias alias mollitia nihil porro voluptatem sit et. Maiores sint autem numquam.\n"
     ]
    }
   ],
   "source": [
    "for line in open('data/lorem_ipsum.txt', 'r'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Schreiben von Dateien funktioniert analog zum Lesen - hier wird der Modus-Parameter der `open`-Funktion auf `w` (write) gesetzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'write' Modus öffnen - bestehende Datei wird überschrieben!\n",
    "with open('output/writing_file.txt', 'w') as outfile:\n",
    "    outfile.writelines(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ sorgt der Parameterwert `a` (append) dafür, dass bestehender Inhalt in der Ausgabedatei nicht überschrieben wird. Stattdessen wird der neue Inhalt angehangen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'append' Modus öffnen - Geschriebenes wird an bestehenden Inhalt angehangen\n",
    "with open('output/appending_file.txt', 'a') as outfile:\n",
    "    outfile.writelines(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir gesehen haben, ist das CSV-Format ein textbasiertes Datenformat. Daher kann es wie eine reguläre Textdatei in Python behandelt werden. Dies hat allerdings seine Tücken, wie das folgende Beispiel zeigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: NYT-Beststellerliste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes sehen wir uns eine CSV-Datei ohne Header an. Hier ist der Inhalt der ersten 10 Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\",\"I Love Dad with The Very Hungry Caterpillar\",\"children\"\r",
      "\r\n",
      "\"2\",\"The Wonderful Things You Will Be\",\"children\"\r",
      "\r\n",
      "\"3\",\"Dr. Seuss's I Love Pop!: A Celebration of Dads\",\"children\"\r",
      "\r\n",
      "\"4\",\"Dragons Love Tacos\",\"children\"\r",
      "\r\n",
      "\"5\",\"How to Babysit a Grandpa\",\"children\"\r",
      "\r\n",
      "\"6\",\"I Wish You More\",\"children\"\r",
      "\r\n",
      "\"7\",\"Grumpy Monkey\",\"children\"\r",
      "\r\n",
      "\"8\",\"The Day the Crayons Quit\",\"children\"\r",
      "\r\n",
      "\"9\",\"Dear Girl,\",\"children\"\r",
      "\r\n",
      "\"10\",\"Rosie Revere, Engineer (Questioneers Collection Series)\",\"children\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head data/nyt_bestsellers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass jeder Datensatz aus 3 Datenfeldern besteht, die wir als Rang, Titel und Genre identifizieren. Entsprechend versuchen wir, diese Werte getrennt auszulesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: \"1\"\n",
      "Title: \"I Love Dad with The Very Hungry Caterpillar\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"2\"\n",
      "Title: \"The Wonderful Things You Will Be\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"3\"\n",
      "Title: \"Dr. Seuss's I Love Pop!: A Celebration of Dads\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"4\"\n",
      "Title: \"Dragons Love Tacos\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"5\"\n",
      "Title: \"How to Babysit a Grandpa\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"6\"\n",
      "Title: \"I Wish You More\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"7\"\n",
      "Title: \"Grumpy Monkey\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"8\"\n",
      "Title: \"The Day the Crayons Quit\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"9\"\n",
      "Title: \"Dear Girl\n",
      "Genre: \"\n",
      "\n",
      "Rank: \"10\"\n",
      "Title: \"Rosie Revere\n",
      "Genre: Engineer (Questioneers Collection Series)\"\n",
      "\n",
      "Rank: \"11\"\n",
      "Title: \"Brawl of the Wild (Dog Man Series #6)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"12\"\n",
      "Title: \"The Meltdown (Diary of a Wimpy Kid Series #13)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"13\"\n",
      "Title: \"Harry Potter and the Sorcerer's Stone (Harry Potter Series #1)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"14\"\n",
      "Title: \"Escape from the Isle of the Lost (Descendants Series #4)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"15\"\n",
      "Title: \"The Lightning Thief (Percy Jackson and the Olympians Series #1)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"16\"\n",
      "Title: \"Captain Underpants and the Big\n",
      "Genre: Bad Battle of the Bionic Booger Boy\n",
      "\n",
      "Rank: \"17\"\n",
      "Title: \"The Bad Guys (The Bad Guys Series #1)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"18\"\n",
      "Title: \"Who Is Michael Jordan?\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"19\"\n",
      "Title: \"Tales from a Not-So-Glam TV Star (Dork Diaries Series #7)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"20\"\n",
      "Title: \"P.S. I Still Love You (To All the Boys I've Loved Before Series #2)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"21\"\n",
      "Title: \"Diary of an Awesome Friendly Kid: Rowley Jefferson's Journal\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"22\"\n",
      "Title: \"PopularMMOs Presents Enter the Mine\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"23\"\n",
      "Title: \"Refugee\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"24\"\n",
      "Title: \"Wonder\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"25\"\n",
      "Title: \"Wishtree\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"26\"\n",
      "Title: \"Katt vs. Dogg\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"27\"\n",
      "Title: \"The First (Endling Series #2)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"28\"\n",
      "Title: \"A Wolf Called Wander\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"29\"\n",
      "Title: \"Aru Shah and the Song of Death (Pandava Series #2)\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"30\"\n",
      "Title: \"Blended\"\n",
      "Genre: \"children\"\n",
      "\n",
      "Rank: \"31\"\n",
      "Title: \"Where the Crawdads Sing\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"32\"\n",
      "Title: \"Unsolved\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"33\"\n",
      "Title: \"Mrs. Everything\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"34\"\n",
      "Title: \"City of Girls\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"35\"\n",
      "Title: \"Tom Clancy Enemy Contact\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"36\"\n",
      "Title: \"The Oracle (Fargo Adventure Series #11)\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"37\"\n",
      "Title: \"Recursion\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"38\"\n",
      "Title: \"Redemption (Amos Decker Series #5)\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"39\"\n",
      "Title: \"The Summer Guests\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"40\"\n",
      "Title: \"On Earth We're Briefly Gorgeous\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"41\"\n",
      "Title: \"Queen Bee\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"42\"\n",
      "Title: \"The Guest Book\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"43\"\n",
      "Title: \"The 18th Abduction (Women's Murder Club Series #18)\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"44\"\n",
      "Title: \"Fall; or\n",
      "Genre: Dodge in Hell\"\n",
      "\n",
      "Rank: \"45\"\n",
      "Title: \"The Silent Patient\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"46\"\n",
      "Title: \"Before We Were Yours\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"47\"\n",
      "Title: \"Little Fires Everywhere\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"48\"\n",
      "Title: \"The Tattooist of Auschwitz\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"49\"\n",
      "Title: \"The Outsider\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"50\"\n",
      "Title: \"The President Is Missing\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"51\"\n",
      "Title: \"The Woman in the Window\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"52\"\n",
      "Title: \"A Gentleman in Moscow\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"53\"\n",
      "Title: \"Eleanor Oliphant Is Completely Fine\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"54\"\n",
      "Title: \"Long Road to Mercy (Atlee Pine Series #1)\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"55\"\n",
      "Title: \"The Mister\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"56\"\n",
      "Title: \"Good Omens: The Nice and Accurate Prophecies of Agnes Nutter\n",
      "Genre: Witch\"\n",
      "\n",
      "Rank: \"57\"\n",
      "Title: \"The Handmaid's Tale\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"58\"\n",
      "Title: \"Big Little Lies (Movie Tie-In)\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"59\"\n",
      "Title: \"The Overstory\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"60\"\n",
      "Title: \"The Death of Mrs. Westaway\"\n",
      "Genre: \"fiction\"\n",
      "\n",
      "Rank: \"61\"\n",
      "Title: \"Unfreedom of the Press\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"62\"\n",
      "Title: \"Songs of America: Patriotism\n",
      "Genre: Protest\n",
      "\n",
      "Rank: \"63\"\n",
      "Title: \"The Pioneers: The Heroic Story of the Settlers Who Brought the American Ideal West\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"64\"\n",
      "Title: \"Howard Stern Comes Again\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"65\"\n",
      "Title: \"Educated\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"66\"\n",
      "Title: \"Becoming\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"67\"\n",
      "Title: \"Sea Stories: My Life in Special Operations\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"68\"\n",
      "Title: \"Siege: Trump Under Fire\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"69\"\n",
      "Title: \"The British Are Coming: The War for America\n",
      "Genre: Lexington to Princeton\n",
      "\n",
      "Rank: \"70\"\n",
      "Title: \"The Enemy of the People: A Dangerous Time to Tell the Truth in America\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"71\"\n",
      "Title: \"More Than Enough: Claiming Space for Who You Are (No Matter What They Say)\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"72\"\n",
      "Title: \"The Moment of Lift: How Empowering Women Changes the World (B&N Exclusive Edition)\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"73\"\n",
      "Title: \"Every Man a Hero: A Memoir of D-Day\n",
      "Genre: the First Wave at Omaha Beach\n",
      "\n",
      "Rank: \"74\"\n",
      "Title: \"The Second Mountain: The Quest for a Moral Life\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"75\"\n",
      "Title: \"One Giant Leap: The Impossible Mission That Flew Us to the Moon\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"76\"\n",
      "Title: \"The Mueller Report\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"77\"\n",
      "Title: \"Born a Crime: Stories from a South African Childhood\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"78\"\n",
      "Title: \"Sapiens: A Brief History of Humankind\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"79\"\n",
      "Title: \"Calypso\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"80\"\n",
      "Title: \"The Mueller Report: The Final Report of the Special Counsel into Donald Trump\n",
      "Genre: Russia\n",
      "\n",
      "Rank: \"81\"\n",
      "Title: \"White Fragility: Why It's So Hard for White People to Talk about Racism\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"82\"\n",
      "Title: \"The Body Keeps the Score: Brain\n",
      "Genre: Mind\n",
      "\n",
      "Rank: \"83\"\n",
      "Title: \"How to Change Your Mind: What the New Science of Psychedelics Teaches Us about Consciousness\n",
      "Genre: Dying\n",
      "\n",
      "Rank: \"84\"\n",
      "Title: \"Just Mercy: A Story of Justice and Redemption\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"85\"\n",
      "Title: \"Indianapolis: The True Story of the Worst Sea Disaster in U.S. Naval History and the Fifty-Year Fight to Exonerate an Innocent Man\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"86\"\n",
      "Title: \"Outliers: The Story of Success\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"87\"\n",
      "Title: \"The Mueller Report: Report on the Investigation into Russian Interference in the 2016 Presidential Election\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"88\"\n",
      "Title: \"Grit: The Power of Passion and Perseverance\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"89\"\n",
      "Title: \"Being Mortal: Medicine and What Matters in the End\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"90\"\n",
      "Title: \"Killers of the Flower Moon: The Osage Murders and the Birth of the FBI\"\n",
      "Genre: \"non-fiction\"\n",
      "\n",
      "Rank: \"91\"\n",
      "Title: \"How to Skimm Your Life\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"92\"\n",
      "Title: \"The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"93\"\n",
      "Title: \"Make Your Bed: Little Things That Can Change Your Life...And Maybe the World\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"94\"\n",
      "Title: \"Stay Sexy & Don't Get Murdered: The Definitive How-to Guide\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"95\"\n",
      "Title: \"Girl\n",
      "Genre: Wash Your Face: Stop Believing the Lies about Who You Are So You Can Become Who You Were Meant to Be\"\n",
      "\n",
      "Rank: \"96\"\n",
      "Title: \"Everything Is F*cked: A Book about Hope\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"97\"\n",
      "Title: \"Girl\n",
      "Genre: Stop Apologizing: A Shame-Free Plan for Embracing and Achieving Your Goals\"\n",
      "\n",
      "Rank: \"98\"\n",
      "Title: \"You Are a Badass: How to Stop Doubting Your Greatness and Start Living an Awesome Life\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"99\"\n",
      "Title: \"Dare to Lead: Brave Work. Tough Conversations. Whole Hearts.\"\n",
      "Genre: \"misc\"\n",
      "\n",
      "Rank: \"100\"\n",
      "Title: \"Medical Medium Celery Juice: The Most Powerful Medicine of Our Time Healing Millions Worldwide\"\n",
      "Genre: \"misc\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beispiel: CSV-Datei auch als Text behandeln\n",
    "for line in open('data/nyt_bestsellers.csv', 'r'):\n",
    "    row = line.split(',') # Zeile am Trennzeichen splitten\n",
    "    rank = row[0]  # Zuordnung der Felder\n",
    "    title = row[1]\n",
    "    genre = row[2].strip()\n",
    "    print(\"Rank: {}\\nTitle: {}\\nGenre: {}\\n\".format(rank, title, genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Bibsonomy-Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung: Auf [bibsonomy](https://www.bibsonomy.org) die Ergebnisse einer Keyword-Suche (z.B. [\"Bibliothek\"](https://www.bibsonomy.org/export/search/Bibliothek)) als CSV exportieren (Limit ggf. vorher auf 1000 erhöhen), lokal speichern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Datei enthält einen Header, der uns die Keys zu den Werten in den Datensätzen liefert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BibliographyType,ISBN,Identifier,Author,Title,Journal,Volume,Number,Month,Pages,Year,Address,Note,URL,Booktitle,Chapter,Edition,Series,Editor,Publisher,ReportType,Howpublished,Institution,Organizations,School,Annote,Custom1,Custom2,Custom3,Custom4,Custom5\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 data/search_Bibliothek.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/search_Bibliothek.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naiver Ansatz über Einlesen als Text und splitten am Komma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BibliographyType', 'ISBN', 'Identifier', 'Author', 'Title', 'Journal', 'Volume', 'Number', 'Month', 'Pages', 'Year', 'Address', 'Note', 'URL', 'Booktitle', 'Chapter', 'Edition', 'Series', 'Editor', 'Publisher', 'ReportType', 'Howpublished', 'Institution', 'Organizations', 'School', 'Annote', 'Custom1', 'Custom2', 'Custom3', 'Custom4', 'Custom5']\n"
     ]
    }
   ],
   "source": [
    "with open(path) as csvfile:\n",
    "    lines = csvfile.readlines()\n",
    "\n",
    "header = lines[0].strip().split(',') # Kopfzeile = erste Datenreihe\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BibliographyType : 1\n",
      "ISBN : \"\"\n",
      "Identifier : \"selbach_bibliothek_2007\"\n",
      "Author : \"Selbach\n",
      "Title :  Michaela & der Fachhochsch.]\n",
      "Journal :  {[Bibliothek}\"\n",
      "Volume : \"Bibliothek 2.0 : neue Perspektiven und Einsatzmöglichkeiten für wissenschaftliche Bibliotheken\"\n",
      "Number : \"\"\n",
      "Month : \n",
      "Pages : \n",
      "Year : \"\"\n",
      "Address : \"\"\n",
      "Note : 2007\n",
      "URL : \"{[Köln]}\"\n",
      "Booktitle : \"\"\n",
      "Chapter : \"\"\n",
      "Edition : \"\"\n",
      "Series : \"\"\n",
      "Editor : \"\"\n",
      "Publisher : \"\"\n",
      "ReportType : \"\"\n",
      "Howpublished : \"{[Bibliothek} der Fachhochsch.]\"\n",
      "Institution : \"\"\n",
      "Organizations : \"\"\n",
      "School : \"\"\n",
      "Annote : \"\"\n",
      "Custom1 : \"\"\n",
      "Custom2 : \"\"\n",
      "Custom3 : \"\"\n",
      "Custom4 : \"\"\n",
      "Custom5 : \"imported\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-89cd50b125db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Zuordnung der Header-Felder zu den Daten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "first_line = lines[1].strip().split(',') # 2. Datenreihe = 1. Datensatz; splitten der Datenfelder am Trennzeichen\n",
    "\n",
    "for i in range(len(first_line)):\n",
    "    print(header[i], ':', first_line[i]) # Zuordnung der Header-Felder zu den Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen, funktioniert dieser naive Ansatz nicht, da auch die Datenfelder Kommata enthalten und somit unser Trennzeichen nicht eindeutig ist. Die Aufteilung der Daten in die korrekten Felder klappt so nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutzen der CSV Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python bietet mit dem `csv` Modul eine komforable Möglichkeit, CSV Dateien zu lesen und zu schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\") # csv Reader Objekt\n",
    "    for row in reader:                          # ... erlaubt zeilenweises Iterieren\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randnotiz: Die drei Zeilen\n",
    "\n",
    "```\n",
    "reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "```\n",
    "\n",
    "können in Kurzform mit einer sogenannten *list comprehension* auch so ausgedrückt werden:\n",
    "\n",
    "```\n",
    "data = [row for row in csv.reader(csvfile, delimiter=\",\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BibliographyType', 'ISBN', 'Identifier', 'Author', 'Title', 'Journal', 'Volume', 'Number', 'Month', 'Pages', 'Year', 'Address', 'Note', 'URL', 'Booktitle', 'Chapter', 'Edition', 'Series', 'Editor', 'Publisher', 'ReportType', 'Howpublished', 'Institution', 'Organizations', 'School', 'Annote', 'Custom1', 'Custom2', 'Custom3', 'Custom4', 'Custom5']\n"
     ]
    }
   ],
   "source": [
    "header = data[0] # Kopfzeile ist auch hier wieder die erste Datenreihe\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BibliographyType : 1\n",
      "ISBN : \n",
      "Identifier : selbach_bibliothek_2007\n",
      "Author : Selbach, Michaela & der Fachhochsch.], {[Bibliothek}\n",
      "Title : Bibliothek 2.0 : neue Perspektiven und Einsatzmöglichkeiten für wissenschaftliche Bibliotheken\n",
      "Journal : \n",
      "Volume : \n",
      "Number : \n",
      "Month : \n",
      "Pages : \n",
      "Year : 2007\n",
      "Address : {[Köln]}\n",
      "Note : \n",
      "URL : \n",
      "Booktitle : \n",
      "Chapter : \n",
      "Edition : \n",
      "Series : \n",
      "Editor : \n",
      "Publisher : {[Bibliothek} der Fachhochsch.]\n",
      "ReportType : \n",
      "Howpublished : \n",
      "Institution : \n",
      "Organizations : \n",
      "School : \n",
      "Annote : \n",
      "Custom1 : \n",
      "Custom2 : \n",
      "Custom3 : imported\n",
      "Custom4 : \n",
      "Custom5 : \n"
     ]
    }
   ],
   "source": [
    "first_line = data[1] # zweite Datenreihe = 1. Datensatz\n",
    "for i in range(len(first_line)):\n",
    "    print(header[i], ':', first_line[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun hat die Zuordnung der Daten zu den Header Feldern korrekt geklappt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere praktische Funktion des CSV-Moduls ist die Möglichkeit, die Daten unmittelbar in ein `Dictionary` einzulesen. Dies setzt voraus, dass die Datei einen Header enthält, welcher die Keys für das Dictionary bereitstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen mit DictReader\n",
    "with open(path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(\"Title: {}\\nAuthors: {}\\nISBN: {}\\n\".format(row['Title'], row['Author'], row['ISBN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Falle des fehlenden Headers werden die Keys manuell definiert, und dem Reader im `fieldnames`-Parameter mitgeteilt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['rank', 'title', 'genre']\n",
    "\n",
    "with open('data/nyt_bestsellers.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',', fieldnames=header)\n",
    "    for row in reader:\n",
    "        print(\"Rank: {}\\nTitle: {}\\nGenre: {}\\n\".format(row['rank'], row['title'], row['genre']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sparen uns jetzt den Versuch, JSON Dateien ebenfalls wie normale Textdateien zu behandeln, da die hierarchische Strukur ungleich schwerer manuell zu parsen wäre.\n",
    "\n",
    "Stattdessen nutzen wir auch hier das passende Python Modul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Datensatz verwenden wir wieder [bibsonomy](https://www.bibsonomy.org/export/search/Bibliothek). Wir stellen das Exportformat auf JSON um und stellen fest, dass uns diesmal kein Download angeboten wird, sondern wir auf eine neue URL umgeleitet werden. Diese notieren wir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bibsonomy.org/json/search/Bibliothek?items=1000&duplicates=merged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt nun zwei mögliche Wege, diese Daten über Python von der url abzurufen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der built-in library urllib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "f = urllib.request.urlopen(url) # f ist eine HTTPResponse\n",
    "result = f.read().decode('utf-8') # utf-8 ist oft die richtige Wahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Ergebnis ist str, muss erst noch als JSON verarbeitet werden (Ergebnis = dict)\n",
    "data = json.loads(result) # json.loads() lädt JSON Daten aus einem String\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit third-party library requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(url) # result ist ein requests.models.Response Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result.json() # das Response-Objekt bietet diese nützliche Methode an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data) # Ergebnis = dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# besser lesbare Ausgabe mittels Einrückungen\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das gleiche, aber durch Nutzung des pprint (pretty print) Moduls\n",
    "from pprint import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können die Daten nun wie ein normales Dictionary behandeln und damit arbeiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['types', 'properties', 'items'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys()) # Anzeige der vorhandenen Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1914\n"
     ]
    }
   ],
   "source": [
    "items = data['items']\n",
    "print(type(items))\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914\n"
     ]
    }
   ],
   "source": [
    "publications = [item for item in items if item['type'] == 'Publication']\n",
    "print(len(publications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "pubs_with_abstracts = [item for item in publications if 'abstract' in item]\n",
    "print(len(pubs_with_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nun die Publikationen nach Sprache filtern und nur die Deutschen behalten. Zum Detektieren der Sprache benötigen wir ein weiteres Modul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das `langdetect` Modul bietet eine einfache, wenn auch nicht immer hundertprozentig korrekte, Methode, textuelle Daten auf ihre Sprache zu überprüfen. Die zentrale Funktion ist dabei `langdetect.detect`, die einen String übergeben bekommt, und einen ISO 639-1 Code zurückgibt, der die Sprachen angibt, also etwa 'de', 'en' oder 'fr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1 = \"Ein Beispielstring auf Deutsch\"\n",
    "detect(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2 = \"Some sample text in English\"\n",
    "detect(ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe dieser Funktion kann man nun beispielweise textuelle Daten filtern und nur diejenigen weiterverarbeiten, die in einer bestimmten Sprache verfasst sind. In diesem Fall wollen wir nur Publikationen behalten, deren Titel auf Deutsch ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_pubs = [item for item in publications if detect(item['label']) == 'de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(german_pubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON-Dateien schreiben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON-Objekte können zur Persistierung natürlich auch wieder als Textdatei gespeichert werden. Hierfür steht die Funktion `json.dump` zur Verfügung, welche als Parameter die Daten (Dictionary oder List), ein Datei(-ähnliches) Objekt, sowie optional die Anzahl der Leerzeichen für Einrückung annimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/german_publications.json', 'w') as outfile:\n",
    "    json.dump(german_pubs, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel zu `json.dump` gibt es auch noch die Funktion `json.dumps`, die wir oben schon gesehen haben. Diese gibt den JSON-String zurück wie er in eine Datei geschrieben werden würde, ohne dies tatsächlich zu tun. So kann man ggf. das Ausgabe-Ergebnis vorher überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(german_pubs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hausaufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suchen Sie auf [bibsonomy](https://www.bibsonomy.org) mit einem selbst gewählten Suchbegriff nach Publikationen. Wählen Sie einen deutschen Suchbegriff, um möglichst viele deutschsprachige Ergebnisse zu erhalten.\n",
    "\n",
    "Greifen Sie mittels der JSON-API auf die Daten zu. Verarbeiten Sie die Publikationsdaten so, dass Sie ausschließlich deutschsprachige Publikationen beibehalten, welche Sie dann in verschiedene Formate überführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lingo-Exportformat erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Eingabeformat für Lingo sieht folgendermaßen aus:\n",
    "\n",
    "```\n",
    "[id.]\n",
    "text.\n",
    "\n",
    "[id.]\n",
    "text.\n",
    "\n",
    "<...>\n",
    "```\n",
    "\n",
    "Die ID muss dabei numerisch und eindeutig sein.\n",
    "\n",
    "Für die Verwendung von Text bieten sich Titel und, wenn vorhanden, Abstract der Publikationen an.\n",
    "\n",
    "Speichern Sie das Ergebnis in einer Datei `bibsonomy_to_lingo.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solr-Exportformat erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solr kann dankenswerterweise JSON-Daten direkt als Import verwenden. Allerdings bietet es sich hier an, die bibsonomy-Daten zunächst noch etwas zu bereinigen. Überlegen Sie, welche Felder Sie möglicherweise umbenennen wollen, und welche Sie für Solr nicht benötigen. Erstellen Sie einen sauberen Export im JSON-Format.\n",
    "\n",
    "Hier ein Beispiel, das zeigt, wie die grundsätzliche Struktur aussehen soll:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id\" : \"978-0641723445\",\n",
    "    \"cat\" : [\"book\",\"hardcover\"],\n",
    "    \"name\" : \"The Lightning Thief\",\n",
    "    \"author\" : \"Rick Riordan\",\n",
    "    \"series_t\" : \"Percy Jackson and the Olympians\",\n",
    "    \"sequence_i\" : 1,\n",
    "    \"genre_s\" : \"fantasy\",\n",
    "    \"inStock\" : true,\n",
    "    \"price\" : 12.50,\n",
    "    \"pages_i\" : 384\n",
    "  }\n",
    ",\n",
    "  {\n",
    "    \"id\" : \"978-1423103349\",\n",
    "    \"cat\" : [\"book\",\"paperback\"],\n",
    "    \"name\" : \"The Sea of Monsters\",\n",
    "    \"author\" : \"Rick Riordan\",\n",
    "    \"series_t\" : \"Percy Jackson and the Olympians\",\n",
    "    \"sequence_i\" : 2,\n",
    "    \"genre_s\" : \"fantasy\",\n",
    "    \"inStock\" : true,\n",
    "    \"price\" : 6.49,\n",
    "    \"pages_i\" : 304\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipps und Hinweise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this\n",
      "1 is\n",
      "2 a\n",
      "3 list\n"
     ]
    }
   ],
   "source": [
    "# mit enumerate kann man über eine Liste iterieren und erhält gleichzeitig einen Zähler:\n",
    "some_list = ['this', 'is', 'a', 'list']\n",
    "for index, item in enumerate(some_list):\n",
    "    print(index, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Tobias', 'age': 31}\n",
      "{'age': 31, 'firstname': 'Tobias'}\n"
     ]
    }
   ],
   "source": [
    "# Keys in Dictionaries lassen sich umbenennen...\n",
    "some_dict = {'name':'Tobias', 'age': 31}\n",
    "print(some_dict)\n",
    "some_dict['firstname'] = some_dict.pop('name')\n",
    "print(some_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'firstname': 'Tobias'}\n"
     ]
    }
   ],
   "source": [
    "# ... und entfernen:\n",
    "some_dict.pop('age', None)\n",
    "print(some_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
