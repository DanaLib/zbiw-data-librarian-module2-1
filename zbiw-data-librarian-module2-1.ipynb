{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZBIW-Zertifikatskurs \"Data Librarian\"\n",
    "# Modul 2.1: Strukturierte Daten und Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap zu Lesen und Schreiben von Textdateien in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'read-only' Modus öffnen\n",
    "file_for_reading = open('data/lorem_ipsum.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nach getaner Arbeit muss die Datei wieder geschlossen werden:\n",
    "file_for_reading.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# besser: 'with' Block benutzen, damit Dateien automatisch geschlossen werden\n",
    "with open('data/lorem_ipsum.txt', 'r') as infile:\n",
    "    data = infile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` ist nun ein Listenobjekt, wobei jedes Listenelement eine Textzeile aus der Datei enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zeilenweise Einlesen ist ebenfalls möglich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lorem_ipsum.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        print(line.strip()) # entferne überflüssigen Whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann den Code noch etwas verkürzen, wenn man die Referenz auf `infile` nicht zusätzlich benötigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('data/lorem_ipsum.txt', 'r'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Schreiben von Dateien funktioniert analog zum Lesen - hier wird der Modus-Parameter der `open`-Funktion auf `w` (write) gesetzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'write' Modus öffnen - bestehende Datei wird überschrieben!\n",
    "with open('output/writing_file.txt', 'w') as outfile:\n",
    "    outfile.writelines(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ sorgt der Parameterwert `a` (append) dafür, dass bestehender Inhalt in der Ausgabedatei nicht überschrieben wird. Stattdessen wird der neue Inhalt angehangen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei im 'append' Modus öffnen - Geschriebenes wird an bestehenden Inhalt angehangen\n",
    "with open('output/appending_file.txt', 'a') as outfile:\n",
    "    outfile.writelines(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir gesehen haben, ist das CSV-Format ein textbasiertes Datenformat. Daher kann es wie eine reguläre Textdatei in Python behandelt werden. Dies hat allerdings seine Tücken, wie das folgende Beispiel zeigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: NYT-Beststellerliste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes sehen wir uns eine CSV-Datei ohne Header an. Hier ist der Inhalt der ersten 10 Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/nyt_bestsellers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass jeder Datensatz aus 3 Datenfeldern besteht, die wir als Rang, Titel und Genre identifizieren. Entsprechend versuchen wir, diese Werte getrennt auszulesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: CSV-Datei auch als Text behandeln\n",
    "for line in open('data/nyt_bestsellers.csv', 'r'):\n",
    "    row = line.split(',') # problematisch, da Komma auch Teil der Daten sein könnte\n",
    "    rank = row[0]  # Zuordnung der Felder\n",
    "    title = row[1]\n",
    "    genre = row[2].strip()\n",
    "    print(\"Rank: {}\\nTitle: {}\\nGenre: {}\\n\".format(rank, title, genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Bibsonomy-Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung: Auf [bibsonomy](https://www.bibsonomy.org) die Suchergebnisse (z.B. [\"Bibliothek\"](https://www.bibsonomy.org/export/search/Bibliothek)) als CSV exportieren (Limit vorher auf 1000 erhöhen), lokal speichern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Datei enthält einen Header, der uns die Keys zu den Werten in den Datensätzen liefert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 data/search_Bibliothek.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/search_Bibliothek.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naiver Ansatz über Einlesen als Text und splitten am Komma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as csvfile:\n",
    "    lines = csvfile.readlines()\n",
    "\n",
    "header = lines[0].strip().split(',') # Kopfzeile = erste Datenreihe\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = lines[1].strip().split(',') # 2. Datenreihe = 1. Datensatz; splitten der Datenfelder am Trennzeichen\n",
    "\n",
    "for i in range(len(header)):\n",
    "    print(header[i], ':', first_line[i]) # Zuordnung der Header-Felder zu den Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen, funktioniert dieser naive Ansatz nicht, da auch die Datenfelder Kommata enthalten und somit unser Trennzeichen nicht eindeutig ist. Die Aufteilung der Daten in die korrekten Felder klappt so nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutzen der CSV Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python bietet mit dem csv Modul eine komforable Möglichkeit, CSV Dateien zu lesen und zu schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as csvfile:\n",
    "    data = [row for row in csv.reader(csvfile, delimiter=\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = data[0] # Kopfzeile ist auch hier wieder die erste Datenreihe\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = data[1] # zweite Datenreihe = 1. Datensatz\n",
    "for i in range(len(first_line)):\n",
    "    print(header[i], ':', first_line[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun hat die Zuordnung der Daten zu den Header Feldern korrekt geklappt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere praktische Funktion des CSV-Moduls ist die Möglichkeit, die Daten unmittelbar in ein `Dictionary` einzulesen. Dies setzt voraus, dass die Datei einen Header enthält, welcher die Keys für das Dictionary bereitstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen mit DictReader\n",
    "with open(path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(\"Title: {}\\nAuthors: {}\\nISBN: {}\\n\".format(row['Title'], row['Author'], row['ISBN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Falle des fehlenden Headers werden die Keys manuell definiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['rank', 'title', 'genre']\n",
    "\n",
    "with open('data/nyt_bestsellers.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',', fieldnames=header)\n",
    "    for row in reader:\n",
    "        print(\"Rank: {}\\nTitle: {}\\nGenre: {}\\n\".format(row['rank'], row['title'], row['genre']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sparen uns jetzt den Versuch, JSON Dateien ebenfalls wie normale Textdateien zu behandeln, da die hierarchische Strukur ungleich schwerer manuell zu parsen wäre.\n",
    "\n",
    "Stattdessen nutzen wir auch hier das passende Python Modul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Datensatz verwenden wir wieder [bibsonomy](https://www.bibsonomy.org/export/search/Bibliothek). Wir stellen das Exportformat auf JSON um und stellen fest, dass uns diesmal kein Download angeboten wird, sondern wir auf eine neue URL umgeleitet werden. Diese notieren wir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bibsonomy.org/json/search/Bibliothek?items=1000&duplicates=merged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt nun zwei mögliche Wege, diese Daten über Python von der url abzurufen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der built-in library urllib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "f = urllib.request.urlopen(url) # f ist eine HTTPResponse\n",
    "result = f.read().decode('utf-8') # utf-8 ist oft die richtige Wahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis ist str, muss erst noch als JSON verarbeitet werden (Ergebnis = dict)\n",
    "data = json.loads(result) # json.loads() lädt JSON Daten aus einem String\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit third-party library requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(url) # result ist ein requests.models.Response Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result.json() # das Response-Objekt bietet diese nützliche Methode an (Ergebnis = dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print in a prettier way\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but using pprint (pretty print) module\n",
    "from pprint import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können die Daten nun wie ein normales Dictionary behandeln und damit arbeiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys()) # Anzeige der vorhandenen Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = data['items']\n",
    "print(type(items))\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = [item for item in items if item['type'] == 'Publication']\n",
    "print(len(publications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs_with_abstracts = [item for item in publications if 'abstract' in item]\n",
    "print(len(pubs_with_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nun die Publikationen nach Sprache filtern und nur die Deutschen behalten. Zum Detektieren der Sprache benötigen wir ein weiteres Modul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_pubs = [item for item in publications if detect(item['label'].strip()) == 'de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(german_pubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in german_pubs:\n",
    "    if 'abstract' in item:\n",
    "        print(item['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON-Dateien schreiben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON-Objekte können zur Persistierung natürlich auch wieder als Textdatei gespeichert werden. Hierfür steht die Funktion `json.dump` zur Verfügung, welche als Parameter die Daten (Dictionary oder List), ein Datei(-ähnliches) Objekt, sowie optional die Anzahl der Leerzeichen für Einrückung annimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/german_publications.json', 'w') as outfile:\n",
    "    json.dump(german_pubs, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel zu `json.dump` gibt es auch noch `json.dumps`, welche den String zurückgibt wie er in eine Datei geschrieben werden würde, ohne dies tatsächlich zu tun. So kann man ggf. das Ausgabe-Ergebnis vorher überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(german_pubs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
